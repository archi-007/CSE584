{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2ZJ2bVocusrT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "squad_dataset = load_dataset('squad')\n",
        "print(squad_dataset['train'][0])"
      ],
      "metadata": {
        "id": "c-uT0q1QvAzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_correct = pd.DataFrame(squad_dataset['train'])\n",
        "df_correct = df_correct[['question', 'answers']]\n",
        "df_correct['Answer'] = df_correct['answers'].apply(lambda x: x['text'][0] if isinstance(x['text'], list) else x['text'])\n",
        "df_correct['Label'] = 1\n",
        "df_correct = df_correct.drop(columns=['answers'])\n",
        "print(df_correct.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "UxMsnnygvFGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_faulty = pd.read_excel('Dataset_CSE584_Project.xlsx')\n",
        "\n",
        "df_faulty['Label'] = 0\n",
        "df = pd.concat([df_faulty, df_correct], ignore_index=True)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "AiE5lxLovI0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "print(\"Data type of 'combined_text' column:\", df['combined_text'].dtype)\n",
        "\n",
        "non_string_rows = df[~df['combined_text'].apply(lambda x: isinstance(x, str))]\n",
        "if not non_string_rows.empty:\n",
        "    print(\"Rows with non-string values:\")\n",
        "    print(non_string_rows)\n",
        "\n",
        "df['combined_text'] = df['combined_text'].astype(str)\n",
        "\n",
        "print(f\"NaN values in 'combined_text': {df['combined_text'].isna().sum()}\")\n",
        "print(f\"Empty strings in 'combined_text': {(df['combined_text'] == '').sum()}\")\n",
        "\n",
        "df['text_length'] = df['combined_text'].apply(len)\n",
        "\n",
        "print(df[['combined_text', 'text_length']].head())\n",
        "\n",
        "df = df[df['text_length'] > 0]\n",
        "\n",
        "df['combined_text'] = df['combined_text'].replace('', 'No valid content')\n",
        "\n",
        "print(f\"NaN values after replacement: {df['combined_text'].isna().sum()}\")\n",
        "print(f\"Empty strings after replacement: {(df['combined_text'] == '').sum()}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Szc7uzLuvMcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X = vectorizer.fit_transform(df['combined_text'])\n",
        "\n",
        "y = df['Label']\n",
        "\n",
        "df['text_length'] = df['combined_text'].apply(len)\n",
        "print(df[['combined_text', 'text_length']].head())\n",
        "\n",
        "df = df[df['text_length'] > 0]\n",
        "print(X.shape)\n"
      ],
      "metadata": {
        "id": "1IHqcyX5vOne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=64, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n"
      ],
      "metadata": {
        "id": "NYCuEOIsvTaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}